{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ87tiu+IdZMiS8YhXXFur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neenz16/MachineLearningProjects/blob/main/neenu_sentiment_analysis_scikit_selfstudyprroject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDPDcnFqWmf3",
        "outputId": "e2975ad5-db6d-4cb3-bad2-7045bd29e0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.3333333333333333\n",
            "'That movie was awesome!' → Positive\n",
            "'I didn’t like the plot.' → Positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd #data manipulation library\n",
        "from sklearn.model_selection import train_test_split # Imports a utility to split your dataset into training and testing sets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #Imports TF-IDF Vectorizer, which turns text into numerical values based on how important a word is.\n",
        "from sklearn.linear_model import LogisticRegression # LR moodel simple and effective classifier for binary tasks like positive/negative sentiment.\n",
        "from sklearn.metrics import accuracy_score # Imports function to calculate accuracy of the model.how well the model performed on the test set.\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'text': [\n",
        "        \"I love this movie!\",\n",
        "        \"This was a great experience\",\n",
        "        \"Absolutely fantastic!\",\n",
        "        \"I hated this\",\n",
        "        \"It was so boring\",\n",
        "        \"Not my type\",\n",
        "        \"Amazing and inspiring\",\n",
        "        \"Worst film ever\",\n",
        "        \"Very enjoyable\",\n",
        "        \"Terrible acting\",\n",
        "        \"Lovely movie!\",\n",
        "        \"Horrible\",\n",
        "        \"Love it!\",\n",
        "        \"Average\",\n",
        "        \"Hate it\",\n",
        "\n",
        "    ],\n",
        "    'label': [1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]  # 1 = Positive, 0 = Negative\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42) #80% train, 20% test.\n",
        "\n",
        "# Vectorize text using TF-IDF ( Converts text → numerical form suitable for the model.)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train) #fit_transform() learns vocabulary from training data and vectorizes.\n",
        "X_test_tfidf = vectorizer.transform(X_test) #transform() uses same vocab to vectorize test data.\n",
        "\n",
        "# Train a Logistic Regression model(Creates a Logistic Regression classifier and trains it on the training data.)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train) # Model learns to associate word patterns with sentiments\n",
        "\n",
        "# Predict and evaluate(Makes predictions on test data and checks accuracy.)\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Try on new text\n",
        "new_text = [\"That movie was awesome!\", \"I didn’t like the plot.\"]\n",
        "new_text_vec = vectorizer.transform(new_text)\n",
        "predictions = model.predict(new_text_vec)\n",
        "\n",
        "for text, pred in zip(new_text, predictions):\n",
        "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    print(f\"'{text}' → {sentiment}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**With real dataset forr sentiment anlysis from NLTK**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IwQpMZesC906"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import movie_reviews\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "Ed1maw4uC8w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download movie_reviews if not already\n",
        "nltk.download('movie_reviews')\n",
        "movie_reviews.categories()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6y6PT7AD1s4",
        "outputId": "baacd744-8fc4-47ab-a2dc-c91a9735a81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load real movie review data\n",
        "texts = []\n",
        "labels = []\n",
        "for category in movie_reviews.categories():  # Loop over 'pos' and 'neg'\n",
        "    for fileid in movie_reviews.fileids(category):  # Get all file ids for this category\n",
        "        texts.append(movie_reviews.raw(fileid))    # Get full review text and add to texts list\n",
        "        labels.append(1 if category == 'pos' else 0)  # Assign label 1 if positive, else 0 for negative"
      ],
      "metadata": {
        "id": "rcFroIcLD4Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})"
      ],
      "metadata": {
        "id": "NlYq10krD6Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "K-la6dufID1_",
        "outputId": "a80f8627-e9ba-45bd-c450-b0733be57232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     plot : two teen couples go to a church party ,...      0\n",
              "1     the happy bastard's quick movie review \\ndamn ...      0\n",
              "2     it is movies like these that make a jaded movi...      0\n",
              "3      \" quest for camelot \" is warner bros . ' firs...      0\n",
              "4     synopsis : a mentally unstable man undergoing ...      0\n",
              "...                                                 ...    ...\n",
              "1995  wow ! what a movie . \\nit's everything a movie...      1\n",
              "1996  richard gere can be a commanding actor , but h...      1\n",
              "1997  glory--starring matthew broderick , denzel was...      1\n",
              "1998  steven spielberg's second epic film on world w...      1\n",
              "1999  truman ( \" true-man \" ) burbank is the perfect...      1\n",
              "\n",
              "[2000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bac524d-29dd-4947-ac81-df550e2d72e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>wow ! what a movie . \\nit's everything a movie...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>richard gere can be a commanding actor , but h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>glory--starring matthew broderick , denzel was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>steven spielberg's second epic film on world w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bac524d-29dd-4947-ac81-df550e2d72e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bac524d-29dd-4947-ac81-df550e2d72e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bac524d-29dd-4947-ac81-df550e2d72e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65a5ac3a-6ac9-447c-b1ec-e375d3cf5aae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65a5ac3a-6ac9-447c-b1ec-e375d3cf5aae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65a5ac3a-6ac9-447c-b1ec-e375d3cf5aae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7ed970f7-8493-433b-9238-76bf0fc08c18\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7ed970f7-8493-433b-9238-76bf0fc08c18 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"the verdict : spine-chilling drama from horror maestro stephen king , featuring an outstanding , oscar-winning performance from kathy bates . \\ngeez , french and saunders had a field day when they set to work on parodying this ! \\nsorry , non-british readers may not be familiar with french and saunders - my apologies . \\nthe pair are british comediennes ( jennifer saunders later went on to become edina monsoon in \\\" absolutely fabulous \\\" ) , who did a series of film spoofs a few years back , including alien , the exorcist and misery . \\nneedless to say , amidst her chucklesome impersonation of kathy bates ( the resemblance was quite uncanny ! ) , dawn french got pretty nasty with her sledgehammer when in reach of jennifer saunder's legs ! \\nbut despite the lingering memory of their sketch , and although i've now seen the film a couple of times now , that \\\" hobbling \\\" scene was no less disturbing ! \\ni'm still left screaming at the telly in revulsion ! \\nthat may be the most memorable scene , but it's certainly not the only worth watching . \\nstephen king , whose film and tv adaptations tend to vary in quality , strikes gold with this simple yet strikingly compelling tale . \\nit's a nicely crafted psychological horror , which effortlessly succeeds in drawing you into the plight of writer phil sheldon ( james caan ) . \\nrescued from a car accident by annie wilkes ( bates ) , who introduces herself as the writer's \\\" number one fan \\\" , he soon becomes her prisoner . \\nboth the script and kathy bates' beautifully masterful performance ( for which she won an oscar ) work arm-in-arm as we quickly begin to realise that beyond her bubbly exterior the woman is basically as nutty as a fruit-cake ( or is that fruity as a nut-cake ? ) . \\nbates relishes her demanding role , and her performance is nothing short of a masterpiece . \\nat times she seems like an innocent victim of her own obsessive behaviour , at times she's a rather tragic character , and more often than not she's just damned scary ! \\nthis is basically a very simple tale , but it achieves a large degree of eloquence in its simplicity . \\nit's an involving , engrossing experience - and considering it's basically a two-hander , mainly set in one locale , it's a remarkable piece of cinema . \\nthere are no jazzy special effects or cheesy action sequences - this one relies solely upon rob reiner's stylish directing and the wonderful performances of bates and caan . \\noh , i haven't really mentioned caan yet - he does a good job as the writer who's a prisoner of his own success ( annie is obsessed with him and his books ) . \\nbut , as you no doubt gathered from the above - bates is well and truly the star of the show . \\nalong with the pig , of course ! \\nanyway , the tension is built-up with masterful aplomb , and some scenes are almost agonisingly tense . \\nthere's the dinner scene where seldon goes to nerve-shattering lengths to poison her wine . \\nhe succeeds , but . . . she \\nknocks the glass over ! \\ni bet you threw a pillow at the screen as well ! \\nin the immortal words of homer j . simpson - \\\" d'oh ! ! \\\" \\nother nerve-wracking scenes include the bit where annie has gone off to town and sheldon starts snooping around the house . \\nwe cut to annie in her car - she's on her way home . . . he \\nrealises this and tries to get back to his room . . . cut \\nto the car again , she's getting near . . . will he make it ? \\nok , so these sequences aren't exactly original , nor perhaps unpredictable - but they work ! \\nboy , do they work ! \\nif a film has you on the edge of your couch , biting your nails and shouting at the screen in suspense , then it's doing something right ! \\nof course , the most nauseating sequence is the aforementioned \\\" hobbling \\\" ! \\nannie realises her captive has been out of his room , and she's going to stop him once and for all . \\ncue a block of wood placed strategically between his ankles and a huge sledgehammer , and . . . i feel ill just thinking about it ! \\nnasty . \\nit all builds up nicely to the final scene where sheldon finally gets the upper hand , and once and for all tries to kill the crazy psycho ! \\nand then we're given one of the most ridiculously over-the-top fight scenes i've ever seen . \\nshe gets hit over the head with a typewriter , set on fire , head smashed against the wall - and she just won't die ! \\nsheldon isn't in terribly good shape either . \\nif it weren't so gorey it would almost be laughable . \\nbut it's a terrifically effective film , and therefore the daft climax is easily overlooked . \\nmisery is a tight , tense , intense and chillingly entertaining thriller . \\nthe directing is first-rate , and the performances - bates in particular - contribute to making this a suitably nightmarish little gem . \\nwonderful stuff . \\n ? - * - * - * - * - * - * - * - * - for more regularly-updated film and tv reviews , check out my site ! \\nhttp : //www . geocities . com/hollywood/bungalow/4960 \\n- * - * - * - * - * - * - * - * - \\n\",\n          \" \\\" the 44 caliber killer has struck again . \\\" \\nstarring john leguizamo , mira sorvino , adrian brody , jennifer esposito , michael rispoli , bebe neuwirth . \\nrated r . \\nsummer of sam will be remembered as a waste of spike lee's abilities . \\nlee is a great filmmaker , often exhibiting kinetic visual flair on par with brian depalma and martin scorsese and a storytelling ability comparable to steven spielberg . \\nbut here , he gets himself into a bind . \\nhis latest effort is a case of a director pretending he has something to say when in reality there is little of substance to absorb from his work . \\nthe summer of 1977 was an unusual summer in new york city . \\nit was the hottest summer on record . \\nto boot , new york's first serial killer was on the loose : calling himself the son of sam , david berkowitz killed 9 people in the new york area and frightened the whole city population . \\nso it was understandable that when nyc was hit with a citywide blackout , people went berserk , causing billions of dollars in damage to the city . \\nthe movie's focus is on a group of twenty-somethings during that fateful summer : vinny ( john leguizamo ) , a club-hopping , adultrous hairdresser , his benevolent wife dionna ( mira sorvino , looking young ) , ritchie ( adrian brody ) , a punk who becomes an outcast as well as a son of sam suspect , a gang of small time mobsters and a few more minor characters . \\nwe follow them through their roller coaster lives , thrown out of whack even more by the recent killings . \\nvinny and dionna have marital problems because vinny cheats and dionna tries to please him , make him stay faithful to her . \\nritchie gets shunned by his group of friends because he has started to become more and more \\\" eccentric , \\\" and has degenerated to the point of dancing in gay night clubs and making porno films with his girlfriend . \\ntensions build and conflicts arise as the anniversary night of son of sam's first murder looms ; the night he promises he will strike again . \\na local gang with too much time on its hands makes a list detailing all of the people that its members think might be suspects . \\nat the top of the list is ritchie . \\nvinny , an unwilling part of the said group , is called upon to set a trap for his friend . \\nas we watch these proceedings , some of which are painfully graphic , the dreaded \\\" so what ? \\\" \\nquestion springs to mind . \\nfrom the way this movie is made , i'd have guessed that spike lee was trying to tell us something , but as i searched deeper it became clear that there is very little there to find . \\nlee touches on so much -- the media , the 70's punk scene , the details of the actual killings , as well as the characters' very personal dilemmas -- but he doesn't bring all of his topics together to form a coherent theme or make a discernible statement . \\nall is not lost if a movie turns out to be hollow ; it can be a saving grace for the film to be enjoyable . \\ntoo bad summer of sam doesn't get any help here . \\nfrankly , it's a bore , a redundant and repetitive two hour and twenty minute film that doesn't entertain beyond its first half hour . \\nthere is no suspense because the film refuses to be fully about the murders and little involving drama because the film is too muddled and its focus too vague . \\nleguizamo's turn as vinnie is annoying and whiny . \\nthe script makes it clear that we're supposed to believe that his character is flawed , but still a good guy . \\nyou'd never guess from his performance . \\nadrian brody and especially mira sorvino fare better . \\nsorvino gives a riveting , touching performance in a banal movie ( i'm tempted to think that i liked her because nearly everything else around her was inane ) ; her character is affecting and her emotions true-to-heart . \\nbrody , too paints an effective portrait of a young guy desperate for attention who gets a little more than he bargained for . \\nsummer of sam has some superficial elements of a good film : it looks great , it has a few notable performances and i suppose it's pretty well directed , in a purely technical way . \\nbut it's also empty , pretentious and boring . \\nlike last year's the thin red line , it's a movie by a director who doesn't know what he wants to say but goes ahead and says it anyway . \\n ? 1999 eugene novikov&#137 ; \\n\",\n          \"in the company of men made a splash at the sundance film festival because , in a year plagued by brothers mcmullen-style , earnestly shallow gen-x angst pictures , it seemed to be actually about something . \\nit angered people , started arguments outside the theater , riled things up . \\nit ignited a spark of excitement in what otherwise has been a disappointing year for independent film . \\nhaving endured my share of the hype , i waited calmly for men to reach the hinterlands wherein i reside , and then checked in to see what all the fuss was about . \\ndoes men live up to its press ? \\nwell , yes it does . \\nand it may make you think twice before you consider dating anyone your office . \\nfor the uninitiated , newcomers aaron eckhart and matt malloy play chad and howard , two corporate drones who are dispatched by their nameless company to a remote branch office for a six week assignment . \\nchad and howard are archetypes , examples of which you can no doubt find in your own place of business . \\nchad is the blond golden boy , genetically engineered for success , the natural charmer who seems to glide effortlessly up the corporate ladder . \\nhoward is chad's boss , but he is weaker of will , the clumsy practitioner of office politics who has achieved his position through dogged persistence rather than raw talent . \\nwe first meet them awaiting their flight in a drab airport lounge . \\nthere chad suggests a scheme worthy of a shakespearean villain : he and howard will find a vulnerable single woman at the branch office , woo her simultaneously , win her love , and then dump her . \\nthe reason ? \\nboth men have recently been dumped themselves , and chad sees an easy route to revenge against the fairer sex . \\n \\\" it'll restore a little dignity to our lives , \\\" he says . \\nhoward , helpless against the force of chad's will , agrees to the plan . \\nthey quickly spot their prey in the form of christine ( stacy edwards ) , a fragile deaf woman working as a temp . \\nchad moves in for the kill , flashing his golden boy smile , plying christine with lunch , then flowers , then dinner . \\nhoward follows suit , though his efforts are in contrast ham-handed and desperate . \\nflattered to have the attention of two eligible men , christine dates them both . \\nyou can guess which one she falls for . \\nsoon a tragic lovers' triangle develops : christine loves chad , chad loves himself , and howard loves christine on the grounds that , since she's handicapped and shy , she just might be wretched and lonely enough to settle for him . \\nadult social interaction never really progresses beyond the level of junior high , does it ? \\nin chad , writer/director labute and actor eckhart have created one of the most chilling monsters ever committed to film-hannibal lector may eat human flesh , but chad is an eater of souls . \\nhis evil is as subtle as a viper's , and as easy as his smile . \\nwe watch in stunned disbelief as he back-stabs coworkers , humiliates his subordinates , and works his deadly venom into christine's heart . \\nhis character would be a joke if he wasn't so chillingly real- all of us have worked with a chad , and some of us may be him . \\nhe's the guy who takes your job and then laughs at you for your weakness . \\nif one of his co-workers should happen to go postal and walk into the office with a bag full of handguns , he had best have his escape route clearly in mind . \\npolitics is his game , and the modern cubicle-filled office is his playground . \\nmen wears the guise of a black comedy , but it functions best as allegory . \\nthe most controversial moment in the film happens when chad humiliates a black temp by asking him how badly he wants to succeed in the company , then forces him to prove it in a manner i won't describe . \\nthe scene is charged with racism and fraught with peril . \\ncould it happen in the real world ? \\nprobably not . \\ntaken as allegory , however , it is representative of the treatment of the meek by the powerful in all facets of society . \\nmaybe it's just the english major in me , but chad , in his motiveless cruelty towards christine and his careful manipulation of howard , can be seen as a symbol of unbridled capitalism , of greed without conscience . \\nthe entire film is a metaphor for social darwinism- only the strong will survive . \\nthe marvel of labute's multi-layered script is that it can disturb each member of its audience in an entirely different way . \\nbut does the film work as entertainment ? \\nits darned funny in spots , particularly in the men's room scenes , which demonstrate the lengths to which guys will go to hold a conversation while engaged in the most basic of bodily functions . \\nit works less well as drama , since by necessity the characters in an allegory tend to be flat ciphers . \\nstacy edwards gives a measured dignity to christine , and succeeds in making us care for her , but by the end of the film we still know nothing about her . \\nlikewise , chad and howard are simply the sum of their actions . \\nby the end of the film you'll feel as if you've met a genuine monster in chad ; perhaps we can also classify men as a horror film . \\ncertainly those expecting a conventional hollywood resolution to the story will walk away disappointed . \\nbut the picture is often mesmerizing , and the script is a work of fine craftsmanship , which makes it well worth your time . \\nlike all good films , it offers a myriad of parallels to the outside world . \\nwhile watching chad in his moment of triumph , i couldn't help but think that bill gates must have felt the same sort of cold , merciless satisfaction when he finally stuck it to steve jobs . \\nthere may be a little bit of chad in all of us , but some of us have taken chad-ness to the level of art . \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape # (row,col)\n",
        "# df.shape[0] #roows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYjj12BWIyma",
        "outputId": "669ed8a0-d870-4ec2-e05d-7870eadffcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1zOVPuYQD8FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Vectorize text using TF-IDF\n",
        "# vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "SlDyDz9LD98Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize text using TF-IDF with n-grams (1-gram and 2-gram)\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "T6e9iik2x6Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "PXeQgQy1D_dF",
        "outputId": "6e5a8168-d8f2-4291-edd4-2bee1bf8916a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJPLBvCaEBMn",
        "outputId": "8c77473f-c611-403f-ae03-b9b6e950019a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try on new text\n",
        "new_text = [\"That movie was awesome!\", \"I didn’t like the plot.\"]\n",
        "new_text_vec = vectorizer.transform(new_text)\n",
        "predictions = model.predict(new_text_vec)\n",
        "\n",
        "for text, pred in zip(new_text, predictions):\n",
        "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    print(f\"'{text}' → {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_TohK4LEDh4",
        "outputId": "4f69227f-6244-4179-8e7f-11eceb05663b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'That movie was awesome!' → Positive\n",
            "'I didn’t like the plot.' → Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Added more text preprocessing:\n",
        "\n",
        "Lowercasing\n",
        "Punctuation removal\n",
        "Lemmatization (using WordNetLemmatizer from NLTK)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SyN-6eXdyh7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnTQtY6jydh5",
        "outputId": "811e33cf-49f0-4d5e-f766-57ccf97c5407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "id": "LauY8QKyyfBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "\n",
        "# Download required NLTK data\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Load real movie review data\n",
        "texts = []\n",
        "labels = []\n",
        "for category in movie_reviews.categories():\n",
        "    for fileid in movie_reviews.fileids(category):\n",
        "        texts.append(movie_reviews.raw(fileid))\n",
        "        labels.append(1 if category == 'pos' else 0)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "# Preprocessing function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    tokens = word_tokenize(text)  # Tokenize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text using TF-IDF with unigrams and bigrams\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('------------------------------------------------')\n",
        "print(\"Test Accuracy with Preprocessing + N-grams:\", accuracy)\n",
        "\n",
        "# Try on new text\n",
        "new_text = [\"That movie was awesome!\", \"I didn’t like the plot.\"]\n",
        "# Preprocess new text before vectorizing\n",
        "new_text_processed = [preprocess_text(text) for text in new_text]\n",
        "new_text_vec = vectorizer.transform(new_text_processed)\n",
        "predictions = model.predict(new_text_vec)\n",
        "\n",
        "print('------------------------------------------------')\n",
        "for text, pred in zip(new_text, predictions):\n",
        "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    print(f\"'{text}' → {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6hmID8vyXqL",
        "outputId": "b3c25b9f-a149-4f8c-f80b-20e331086ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "Test Accuracy with Preprocessing + N-grams: 0.815\n",
            "------------------------------------------------\n",
            "'That movie was awesome!' → Positive\n",
            "'I didn’t like the plot.' → Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Logistic Regression: Good baseline for binary classification.\n",
        "\n",
        "* Random Forest: Ensemble of decision trees → reduces overfitting, better accuracy.\n",
        "* XGBoost: Boosted trees built sequentially to correct mistakes of previous ones, super popular in competitions.\n",
        "* LightGBM: Similar to XGBoost but faster, uses histogram-based learning, better with large data.\n",
        "\n",
        "\n",
        "---\n",
        "Integrate Random Forest and XGBoost to baseline sentiment analysis code:\n",
        "\n",
        "with preprocessing (lowercase, punctuation removal, lemmatization), n-grams (1,2), stopword removal and RandomForest & XGBoost\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JoIL7Bqm1kf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import movie_reviews, stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "# Download resources\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load data\n",
        "texts, labels = [], []\n",
        "for category in movie_reviews.categories():\n",
        "    for fileid in movie_reviews.fileids(category):\n",
        "        texts.append(movie_reviews.raw(fileid))\n",
        "        labels.append(1 if category == 'pos' else 0)\n",
        "\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "# Text Preprocessing Function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorizer with n-grams\n",
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "rf_preds = rf_model.predict(X_test_tfidf)\n",
        "rf_acc = accuracy_score(y_test, rf_preds)\n",
        "print('------------------------------------------------')\n",
        "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")\n",
        "\n",
        "# XGBoost Model\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train_tfidf, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test_tfidf)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print('------------------------------------------------')\n",
        "print(f\"XGBoost Accuracy: {xgb_acc:.4f}\")\n",
        "\n",
        "# Try on new text\n",
        "new_text = [\"That movie was awesome!\", \"I didn’t like the plot.\"]\n",
        "new_text_preprocessed = [preprocess_text(t) for t in new_text]\n",
        "new_text_vec = vectorizer.transform(new_text_preprocessed)\n",
        "\n",
        "# Predictions from both models\n",
        "rf_sentiments = rf_model.predict(new_text_vec)\n",
        "xgb_sentiments = xgb_model.predict(new_text_vec)\n",
        "print('------------------------------------------------')\n",
        "\n",
        "for text, rf_pred, xgb_pred in zip(new_text, rf_sentiments, xgb_sentiments):\n",
        "    rf_label = \"Positive\" if rf_pred == 1 else \"Negative\"\n",
        "    xgb_label = \"Positive\" if xgb_pred == 1 else \"Negative\"\n",
        "    print(f\"'{text}' → RandomForest: {rf_label}, XGBoost: {xgb_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duAEZ9tO2FLR",
        "outputId": "07035df6-096d-4110-8e58-3114b66b206c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "Random Forest Accuracy: 0.8075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:00:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "XGBoost Accuracy: 0.7950\n",
            "------------------------------------------------\n",
            "'That movie was awesome!' → RandomForest: Positive, XGBoost: Positive\n",
            "'I didn’t like the plot.' → RandomForest: Negative, XGBoost: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Implement a professional-grade, pretrained transformer model: BERT using\n",
        "**HuggingFace Transformers**.\n",
        "\n",
        "**BERT** (Bidirectional Encoder Representations from Transformers) is a deep learning transformer model pretrained on large text corpora (like Wikipedia) — it understands context better because it reads text both left-to-right and right-to-left.\n",
        "\n",
        "For sentiment analysis, we can fine-tune or directly use a pretrained sentiment classifier model (like distilbert-base-uncased-finetuned-sst-2-english from HuggingFace).\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Zk-Wr31M6YqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t3wv_ngV6M9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbKcOeHU6W3m",
        "outputId": "fc71f498-0606-493c-9971-4374c4239556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from transformers import pipeline\n",
        "\n",
        "# Download the dataset\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "# Load pretrained sentiment-analysis pipeline (DistilBERT fine-tuned on SST-2)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Prepare texts from movie_reviews\n",
        "texts = []\n",
        "for fileid in movie_reviews.fileids():\n",
        "    review_text = movie_reviews.raw(fileid)\n",
        "    texts.append(review_text[:512])  # truncate to first 512 characters\n",
        "\n",
        "# Limit for demo (say first 10 for quick run — can remove limit for full dataset)\n",
        "texts = texts[:10]\n",
        "\n",
        "# Get predictions\n",
        "results = sentiment_pipeline(texts)\n",
        "\n",
        "# Print results\n",
        "for text, result in zip(texts, results):\n",
        "    label = result['label']\n",
        "    score = result['score']\n",
        "    print(f\"Sentiment: {label} (confidence: {score:.2f})\\n---\\n{text[:300]}...\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibJ7XDoi6L6C",
        "outputId": "65a67109-f647-42a4-8c1f-1e71d51f636f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: NEGATIVE (confidence: 0.99)\n",
            "---\n",
            "plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
            "what's the deal ? \n",
            "watch the movie and \" sorta \" find out . . . \n",
            "critique : a mind-fuck movie for the...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 1.00)\n",
            "---\n",
            "the happy bastard's quick movie review \n",
            "damn that y2k bug . \n",
            "it's got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they ...\n",
            "\n",
            "Sentiment: POSITIVE (confidence: 0.92)\n",
            "---\n",
            "it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \n",
            "based on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \n",
            "however , things go ...\n",
            "\n",
            "Sentiment: POSITIVE (confidence: 0.97)\n",
            "---\n",
            " \" quest for camelot \" is warner bros . ' first feature-length , fully-animated attempt to steal clout from disney's cartoon empire , but the mouse has no reason to be worried . \n",
            "the only other recent challenger to their throne was last fall's promising , if flawed , 20th century fox production \" an...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 0.99)\n",
            "---\n",
            "synopsis : a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal accident and then falls in love with the boy's mother , a fledgling restauranteur . \n",
            "unsuccessfully attempting to gain the woman's favor , he takes pictures of her and kills a number of people in his way...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 0.95)\n",
            "---\n",
            "capsule : in 2176 on the planet mars police taking into custody an accused murderer face the title menace . \n",
            "there is a lot of fighting and not a whole lot of story otherwise . \n",
            "john carpenter reprises so many ideas from his previous films , especially assault on precinct 13 , that the new film come...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 1.00)\n",
            "---\n",
            "so ask yourself what \" 8mm \" ( \" eight millimeter \" ) is really all about . \n",
            "is it about a wholesome surveillance man who loses sight of his values after becoming enmeshed in the seedy , sleazy underworld of hardcore pornography ? \n",
            "is it about the business itself , how , bubbling just beneath the su...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 1.00)\n",
            "---\n",
            "that's exactly how long the movie felt to me . \n",
            "there weren't even nine laughs in nine months . \n",
            "it's a terrible mess of a movie starring a terrible mess of a man , mr . hugh grant , a huge dork . \n",
            "it's not the whole oral-sex/prostitution thing ( referring to grant , not me ) that bugs me , it's the...\n",
            "\n",
            "Sentiment: POSITIVE (confidence: 0.98)\n",
            "---\n",
            "call it a road trip for the walking wounded . \n",
            "stellan skarsg ? rd plays such a convincingly zombified drunken loser that it's difficult to spend nearly two hours of screen time in his smelly , boozed-out presence . \n",
            "yet this ever-reliable swedish actor adds depth and significance to the otherwise p...\n",
            "\n",
            "Sentiment: NEGATIVE (confidence: 1.00)\n",
            "---\n",
            "plot : a young french boy sees his parents killed before his eyes by tim roth , oops . . . i \n",
            "mean , an evil man . \n",
            "he vows revenge on that man and is taught the ways of the musketeer by some old dude who used to be one himself ? \n",
            "anyway , fourteen years go by and . . . arrgh , well , you know the r...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hyperparameter Tuning (GridSearchCV)\n",
        "To find the best parameters for the model - to maximize its performance.\n",
        "\n",
        " optimize the model's performance.\n",
        "find the optimal settings for parameters such as learning rate, number of estimators, max depth, etc.\n",
        "\n",
        "NOTE:\n",
        "Comparison to other techniques:\n",
        "\n",
        "RandomizedSearchCV: Tries random parameter combinations (faster, but less exhaustive)\n",
        "\n",
        "Bayesian Optimization: Smarter, probabilistic parameter search (like Optuna or Hyperopt)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xB7r5SAKuwQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# performing hyperparameter tuning on a LightGBM classifier using GridSearchCV from scikit-learn.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with LightGBM model\n",
        "grid_search = GridSearchCV(estimator=lgb.LGBMClassifier(), param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Best Params:\", accuracy)\n"
      ],
      "metadata": {
        "id": "RBnPjxHJuvvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ToQn6srV6LpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified code with a real text dataset (sklearn's built-in movie_reviews dataset)\n",
        "Added the following to check difference or improvements in accurracy scores:\n",
        "Preprocess the text (lowercase, remove punctuation)\n",
        "1) Add stop words removal\n",
        "2) Try with ngram_range=(1,2) for unigrams + bigrams\n",
        "\n",
        "Show accuracy scores separately:\n",
        "\n",
        "\n",
        "*   Basic TF-IDF\n",
        "*   TF-IDF + stopword removal\n",
        "*   TF-IDF + stopwords + ngram\n",
        "\n"
      ],
      "metadata": {
        "id": "iOf2NYwu-rw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Notes:\n",
        "# pandas — for working with tabular data (like CSV files or dataframes)\n",
        "# string — provides string operations (used to remove punctuation)\n",
        "# train_test_split — splits your data into training and testing subsets\n",
        "# TfidfVectorizer — converts text into numerical TF-IDF vectors\n",
        "# LogisticRegression — a simple yet effective model for classification tasks\n",
        "# accuracy_score — to measure how well your model predicts\n",
        "# fetch_20newsgroups — built-in text dataset loader from sklearn"
      ],
      "metadata": {
        "id": "qxYAMYDI_WTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load real dataset (binary classification — 2 categories for simplicity)\n",
        "categories = ['rec.sport.baseball', 'sci.med']  # Positive-ish & Negative-ish contexts\n",
        "dataset = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "X0jmtGEHAsKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "-_PFrC2OCGow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({'text': dataset.data, 'label': dataset.target})"
      ],
      "metadata": {
        "id": "mOuALxh4_0k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function (lowercase + remove punctuation)\n",
        "def preprocess(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "-W3fxq44_4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "fHz3Sj-F_89w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QWl1capQ__aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic TF-IDF (no stopwords, no ngrams)\n",
        "vectorizer_basic = TfidfVectorizer()\n",
        "X_train_basic = vectorizer_basic.fit_transform(X_train)\n",
        "X_test_basic = vectorizer_basic.transform(X_test)\n",
        "\n",
        "model_basic = LogisticRegression(max_iter=500)\n",
        "model_basic.fit(X_train_basic, y_train)\n",
        "pred_basic = model_basic.predict(X_test_basic)\n",
        "accuracy_basic = accuracy_score(y_test, pred_basic)\n",
        "print(f\"Accuracy with Basic TF-IDF: {accuracy_basic:.4f}\")"
      ],
      "metadata": {
        "id": "5IHfuYIEAJ37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF with stopwords removal\n",
        "vectorizer_stop = TfidfVectorizer(stop_words='english')\n",
        "X_train_stop = vectorizer_stop.fit_transform(X_train)\n",
        "X_test_stop = vectorizer_stop.transform(X_test)\n",
        "\n",
        "model_stop = LogisticRegression(max_iter=500)\n",
        "model_stop.fit(X_train_stop, y_train)\n",
        "pred_stop = model_stop.predict(X_test_stop)\n",
        "accuracy_stop = accuracy_score(y_test, pred_stop)\n",
        "print(f\"Accuracy with Stopwords Removed: {accuracy_stop:.4f}\")\n"
      ],
      "metadata": {
        "id": "B5JHLrg4AMC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF with stopwords removal + ngrams (unigrams + bigrams)\n",
        "vectorizer_ngram = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "X_train_ngram = vectorizer_ngram.fit_transform(X_train)\n",
        "X_test_ngram = vectorizer_ngram.transform(X_test)\n",
        "\n",
        "model_ngram = LogisticRegression(max_iter=500)\n",
        "model_ngram.fit(X_train_ngram, y_train)\n",
        "pred_ngram = model_ngram.predict(X_test_ngram)\n",
        "accuracy_ngram = accuracy_score(y_test, pred_ngram)\n",
        "print(f\"Accuracy with Stopwords + Ngrams: {accuracy_ngram:.4f}\")"
      ],
      "metadata": {
        "id": "vm28nXD2ANrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}